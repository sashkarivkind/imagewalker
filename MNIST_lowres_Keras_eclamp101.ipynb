{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import misc\n",
    "# from RL_networks import Stand_alone_net\n",
    "# import pickle\n",
    "# import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "# np.__version__\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import SYCLOP_env as syc\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import keras_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "\n",
    "mnist = MNIST('/home/labs/ahissarlab/bnassa/datasets/mnist/')\n",
    "images, labels = mnist.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for low resolution lens on syclop\n",
    "def bad_res101(img,res):\n",
    "    sh=np.shape(img)\n",
    "    dwnsmp=cv2.resize(img,res, interpolation = cv2.INTER_AREA)\n",
    "    upsmp = cv2.resize(dwnsmp,sh, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return upsmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_eclamp_traj(timesteps = 5 ,res = 6, random_dir = True):\n",
    "def generate_eclamp_traj(timesteps = 5 ,res = 6):\n",
    "    fixed_dir = [0, 0, np.pi/2.0, np.pi, -np.pi/2.0, 0, np.pi/2.0, np.pi, -np.pi/2.0, 0, np.pi/2.0, np.pi, -np.pi/2.0]\n",
    "    traj_list = []\n",
    "\n",
    "    #Set the sensor and the agent\n",
    "    img=misc.build_mnist_padded(1./256*np.reshape(images[0],[1,28,28]))\n",
    "    scene = syc.Scene(image_matrix=img)\n",
    "    sensor = syc.Sensor(winx=56,winy=56,centralwinx=28,centralwiny=28)\n",
    "    agent = syc.Agent(max_q = [scene.maxx-sensor.hp.winx,scene.maxy-sensor.hp.winy])\n",
    "    sensor.hp.resolution_fun = lambda x: bad_res101(x,(res,res))\n",
    "#     sensor.hp.resolution_fun = lambda x: bad_res101(x,(res,res))\n",
    "\n",
    "\n",
    "    for img_num,img in enumerate(images):\n",
    "        #Set the padded image\n",
    "        img=misc.build_mnist_padded(1./256*np.reshape(img,[1,28,28]))\n",
    "    #     print(\"img: \", img_num)\n",
    "\n",
    "        #Set the scene\n",
    "        scene = syc.Scene(image_matrix=img)\n",
    "\n",
    "        starting_point = np.array([agent.max_q[0]//2,agent.max_q[1]//2],dtype=int)\n",
    "#         starting_point += np.random.randint(-5,5,2)\n",
    "        \n",
    "        #Set the agent & the first coord\n",
    "        steps  = []\n",
    "        agent.reset()\n",
    "        \n",
    "        agent.set_manual_q(starting_point)\n",
    "        q1, ssteps = sensor.eclamp_step(scene, agent, fixed_dir[0]+np.pi)#taking one step in the opposite direction\n",
    "        steps.append(q1)\n",
    "#         steps.append(starting_point*1)\n",
    "        \n",
    "#         agent.set_manual_q(q1)\n",
    "#         sensor.update(scene, agent)\n",
    "        \n",
    "        for j in range(timesteps):\n",
    "#             if random_dir:\n",
    "#                 ssteps = sensor.eclamp_max_substeps\n",
    "#                 while ssteps == sensor.eclamp_max_substeps:\n",
    "#                     agent.set_manual_q(steps[-1])\n",
    "#                     phi = 2 * np.pi * random.random()\n",
    "#                     q1, ssteps = sensor.eclamp_step(scene, agent, phi)\n",
    "#             else:\n",
    "#             agent.set_manual_q(steps[j])\n",
    "            phi = fixed_dir[j]\n",
    "            q1, ssteps = sensor.eclamp_step(scene, agent, phi)\n",
    "#             print(q1,ssteps)\n",
    "            \n",
    "            if j==0:\n",
    "                q1 = starting_point\n",
    "                agent.set_manual_q(q1)\n",
    "#                 print(q1,'0')\n",
    "                \n",
    "            steps.append(q1)\n",
    "\n",
    "        q_sequence = np.array(steps).astype(int)\n",
    "        traj_list.append(q_sequence)\n",
    "        \n",
    "    return traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fixed_traj(q_sequence):\n",
    "    \n",
    "    traj_list = []\n",
    "    for img_num,img in enumerate(images):\n",
    "        traj_list.append(q_sequence)\n",
    "    \n",
    "    return traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fixed_traj_rand_start_point():\n",
    "     \n",
    "    traj_diff = [[2,0], [0,2], [-2,0], [0,-3]]\n",
    "    traj_list = []\n",
    "\n",
    "    for img_num,img in enumerate(images):\n",
    "        starting_point = np.array([agent.max_q[0]//2,agent.max_q[1]//2])\n",
    "        starting_point += np.random.randint(-5,5,2)\n",
    "        \n",
    "        steps = []\n",
    "        steps.append(starting_point*1)\n",
    "        for j in range(4):\n",
    "            starting_point += traj_diff[j]\n",
    "            steps.append(starting_point*1)\n",
    "                \n",
    "        \n",
    "        traj_list.append(steps)\n",
    "    \n",
    "    return traj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(images, labels, res, steps = 5, mixed_state = True, add_traject = True,\n",
    "                   trajectory_list=None,return_datasets=False, dvs_img = False):\n",
    "    '''\n",
    "    Creates a torch dataloader object of syclop outputs \n",
    "    from a list of images and labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images : List object holding the images to proces\n",
    "    labels : List object holding the labels\n",
    "    res : resolution dawnsampling factor - to be used in cv.resize(orig_img, res)\n",
    "    sample: the number of samples to have in syclop\n",
    "    mixed_state : if False, use the same trajectory on every image.\n",
    "    return_datasets: rerutns datasets rather than dataloaders\n",
    "    Returns\n",
    "    -------\n",
    "    train_dataloader, test_dataloader - torch DataLoader class objects\n",
    "\n",
    "    '''\n",
    "    count = 0\n",
    "    ts_images = []\n",
    "    dvs_images = []\n",
    "    q_seq = []\n",
    "    count = 0\n",
    "    #create subplot to hold examples from the dataset\n",
    "    fig, ax = plt.subplots(2,5)\n",
    "    i = 0 #indexises for the subplot for image and for syclop vision\n",
    "    for img_num,img in enumerate(images):\n",
    "        orig_img = np.reshape(img,[28,28])\n",
    "        #Set the padded image\n",
    "        img=misc.build_mnist_padded(1./256*np.reshape(img,[1,28,28]))\n",
    "        \n",
    "        if count < 5:\n",
    "            ax[0,i].imshow(orig_img) \n",
    "            plt.title(labels[count])\n",
    "        #Set the sensor and the agent\n",
    "        scene = syc.Scene(image_matrix=img)\n",
    "        sensor = syc.Sensor(winx=56,winy=56,centralwinx=28,centralwiny=28)\n",
    "        agent = syc.Agent(max_q = [scene.maxx-sensor.hp.winx,scene.maxy-sensor.hp.winy])\n",
    "        #Setting the coordinates to visit\n",
    "        if trajectory_list is None:\n",
    "            starting_point = np.array([agent.max_q[0]//2,agent.max_q[1]//2])\n",
    "            starting_point += np.random.randint(-5,5,2)#eldad\n",
    "            steps  = []\n",
    "            for j in range(steps):\n",
    "                steps.append(starting_point*1)\n",
    "                starting_point += np.random.randint(-5,5,2) \n",
    "\n",
    "            if mixed_state:\n",
    "                q_sequence = np.array(steps).astype(int)\n",
    "            else:\n",
    "                if count == 0:\n",
    "                    q_sequence = np.array(steps).astype(int)\n",
    "        else:\n",
    "            q_sequence = np.array(trajectory_list[img_num]).astype(int)\n",
    "        #Setting the resolution function - starting with the regular resolution\n",
    "        sensor.hp.resolution_fun = lambda x: bad_res101(x,(res,res))\n",
    "        #Create empty lists to store the syclops outputs\n",
    "        imim=[]\n",
    "        dimim=[]\n",
    "        agent.set_manual_trajectory(manual_q_sequence=q_sequence)\n",
    "#         if count < 5:\n",
    "#             print(q_sequence.shape)\n",
    "#         #setting first view for dvs - preventing \"flashing\"\n",
    "#         if dvs_dvs_img:\n",
    "#             agent.manual_act()\n",
    "#             sensor.update(scene, agent)\n",
    "            \n",
    "        for t in range(steps):\n",
    "            agent.manual_act()\n",
    "            sensor.update(scene, agent)\n",
    "            imim.append(sensor.central_frame_view)\n",
    "            dimim.append(sensor.central_dvs_view)\n",
    "        #Create a unified matrix from the list\n",
    "        if count < 5:\n",
    "            ax[1,i].imshow(imim[0]) \n",
    "            plt.title(labels[count])\n",
    "            i+=1\n",
    "            \n",
    "\n",
    "        imim = np.array(imim)\n",
    "        dimim = np.array(dimim)\n",
    "        #Add current proccessed image to lists\n",
    "        ts_images.append(imim)\n",
    "        dvs_images.append(dimim[1:])\n",
    "        q_seq.append(q_sequence)\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    if add_traject: #If we add the trjectories the train list will become a list of lists, the images and the \n",
    "        #corrosponding trajectories, we will change the dataset structure as well. Note the the labels stay the same.\n",
    "        if dvs_img:\n",
    "            ts_train = [dvs_images[:55000], q_seq[:55000]] \n",
    "            ts_val = [dvs_images[55000:], q_seq[55000:]]\n",
    "        else:\n",
    "            ts_train = [ts_images[:55000], q_seq[:55000]] \n",
    "            ts_val = [ts_images[55000:], q_seq[55000:]]\n",
    "    else:\n",
    "        if dvs_img:\n",
    "            dvs_train = dvs_images[:55000]\n",
    "            dvs_val = dvs_images[55000:]\n",
    "        else:\n",
    "            ts_train = ts_images[:55000]\n",
    "            ts_val = ts_images[55000:]\n",
    "    \n",
    "    train_labels = labels[:55000]\n",
    "    val_labels = labels[55000:]\n",
    "    \n",
    "    \n",
    "    class mnist_dataset(Dataset):\n",
    "        def __init__(self, data, labels, add_traject = False, transform = None):\n",
    "\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "\n",
    "            self.add_traject = add_traject\n",
    "            self.transform = transform\n",
    "        def __len__(self):\n",
    "            if self.add_traject: \n",
    "                return len(self.data[0]) \n",
    "            else: return len(self.data[0])\n",
    "\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            '''\n",
    "            args idx (int) :  index\n",
    "\n",
    "            returns: tuple(data, label)\n",
    "            '''\n",
    "            if self.add_traject:\n",
    "                img_data = self.data[0][idx] \n",
    "                traject_data = self.data[1][idx]\n",
    "                label = self.labels[idx]\n",
    "                return img_data, traject_data, label\n",
    "            else:\n",
    "                data = self.data[idx]\n",
    "\n",
    "\n",
    "\n",
    "            if self.transform:\n",
    "                data = self.transform(data)\n",
    "                return data, label\n",
    "            else:\n",
    "                return data, label\n",
    "\n",
    "        def dataset(self):\n",
    "            return self.data\n",
    "        def labels(self):\n",
    "            return self.labels\n",
    "        \n",
    "    train_dataset = mnist_dataset(ts_train, train_labels,add_traject = True)\n",
    "    test_dataset = mnist_dataset(ts_val, val_labels,add_traject = True)\n",
    "    batch = 64\n",
    "#     train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch, shuffle = True)\n",
    "#     test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = batch, shuffle = True)\n",
    "\n",
    "    if return_datasets:\n",
    "        return train_dataset, test_dataset\n",
    "    else:\n",
    "        return train_dataloader, test_dataloader, ts_train, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_xy(dataset, timesteps_s = 0, timesteps_e = 5):\n",
    "    dataset_x1 = [uu[0] for uu in dataset]\n",
    "    dataset_x2 = [uu[1] for uu in dataset]\n",
    "    dataset_y = [uu[-1] for uu in dataset]\n",
    "    return (np.array(dataset_x1)[...,np.newaxis],np.array(dataset_x2)[:,timesteps_s:timesteps_e,:]),np.array(dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = 6\n",
    "ts = 5\n",
    "\n",
    "dvsi = True\n",
    "if dvsi:\n",
    "#     q_seq = [[34,36],[36,36],[38,36],[38,38],[36,38],[36,36]]#first coord is supposed to be ignored\n",
    "#     traj_l = generate_fixed_traj(q_seq)\n",
    "\n",
    "    traj_l = generate_eclamp_traj(ts, res)\n",
    "\n",
    "    train_dataset, test_dataset = create_dataset(images, labels,\n",
    "                                             res = res,return_datasets=True,\n",
    "                                             steps = ts+1,\n",
    "                                             dvs_img = dvsi,trajectory_list = traj_l)\n",
    "\n",
    "    train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset, 1, ts+1)\n",
    "    test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset, 1, ts+1)\n",
    "\n",
    "else:\n",
    "    q_seq = [[36,36],[38,36],[38,38],[36,38],[36,35]]\n",
    "    traj_l = generate_fixed_traj(q_seq)\n",
    "    \n",
    "    #     traj_l = generate_eclamp_traj(ts, res)\n",
    "\n",
    "    train_dataset, test_dataset = create_dataset(images, labels,\n",
    "                                             res = res,return_datasets=True,\n",
    "                                             steps = ts,\n",
    "                                             dvs_img = dvsi,trajectory_list = traj_l)\n",
    "\n",
    "    train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset, 0, ts)\n",
    "    test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset, 0, ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 5, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# traj_l_const_start_100 = traj_l\n",
    "\n",
    "# print(traj_l[0])\n",
    "# random.shuffle(traj_l)\n",
    "# print(traj_l[0])\n",
    "\n",
    "train_dataset, test_dataset = create_dataset(images, labels,\n",
    "                                             res = res,return_datasets=True,\n",
    "                                             steps = ts+1,\n",
    "                                             dvs_img = dvsi,trajectory_list = traj_l)\n",
    "\n",
    "train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset, 1, ts+1)\n",
    "test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset, 1, ts+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn102 = keras_networks.rnn_model_102(n_timesteps=ts,\n",
    "                                      lr=2e-3,dropout=0.0,\n",
    "                                      ignore_input_B=True,\n",
    "                                      rnn_type='gru',\n",
    "                                      input_size=(28,28,1),\n",
    "                                      conv_fe=False)\n",
    "  \n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = rnn102.fit(\n",
    "            train_dataset_x,\n",
    "            train_dataset_y,\n",
    "            batch_size=64,\n",
    "            epochs=2,\n",
    "            # We pass some validation for\n",
    "            # monitoring validation loss and metrics\n",
    "            # at the end of each epoch\n",
    "            validation_data=(test_dataset_x, test_dataset_y)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_keras_lowres_eclamp(res_list = [6], timesteps = 5, random_dir = False, dvs_imgs = False, ignore_seq = False, cnn = True):\n",
    "    # RES_LIST = [4, 6, 8, 10, 12]\n",
    "    # RES_LIST = [6]\n",
    "#     TIMESTEPS = 5\n",
    "\n",
    "    traj_l = []\n",
    "#     q_seq = [[36,36],[38,36],[38,38],[36,38],[36,35]]\n",
    "    acc = np.zeros(len(res_list))\n",
    "    val_acc = np.zeros(len(res_list))\n",
    "    for indx,res in enumerate(res_list):\n",
    "\n",
    "    #     traj_l = generate_fixed_traj(q_seq)\n",
    "        traj_l = generate_eclamp_traj(timesteps, res, random_dir = False)\n",
    "    #     traj_l = generate_fixed_traj_rand_start_point()\n",
    "\n",
    "        train_dataset, test_dataset = create_dataset(images, labels,\n",
    "                                                     res = res,return_datasets=True, \n",
    "                                                     dvs_images = dvs_imgs,trajectory_list = traj_l)\n",
    "    #     train_dataset, test_dataset = create_dataset(images, labels,res = res,return_datasets=True)\n",
    "\n",
    "        train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset, timesteps)\n",
    "        test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset, timesteps)\n",
    "\n",
    "        rnn102 = keras_networks.rnn_model_102(n_timesteps=timesteps,\n",
    "                                              lr=1e-3,dropout=0.0,\n",
    "                                              ignore_input_B = ignore_seq,\n",
    "                                              rnn_type='gru',\n",
    "                                              input_size=(28,28,1),\n",
    "                                              conv_fe=cnn)\n",
    "    #     rnn = rnn_model(timesteps)\n",
    "\n",
    "        print(\"Fit model on training data\")\n",
    "        history = rnn102.fit(\n",
    "            train_dataset_x,\n",
    "            train_dataset_y,\n",
    "            batch_size=64,\n",
    "            epochs=1,\n",
    "            # We pass some validation for\n",
    "            # monitoring validation loss and metrics\n",
    "            # at the end of each epoch\n",
    "            validation_data=(test_dataset_x, test_dataset_y)) #(validation_images, validation_labels)\n",
    "\n",
    "\n",
    "        acc[indx] = history.history['sparse_categorical_accuracy'][0]\n",
    "        val_acc[indx] = history.history['val_sparse_categorical_accuracy'][0]\n",
    "\n",
    "    return acc, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_LIST = [4, 6, 8, 10, 12]\n",
    "\n",
    "# acc_eclamp_base, val_acc_eclamp_base = run_keras_lowres_eclamp(res_list = RES_LIST, \n",
    "#                                                                timesteps = 5, random_dir = False, \n",
    "#                                                                dvs_imgs = False, ignore_seq = False, cnn = True)\n",
    "# acc_eclamp_base_nocnn, val_acc_eclamp_nocnn = run_keras_lowres_eclamp(res_list = RES_LIST, \n",
    "#                                                                timesteps = 5, random_dir = False, \n",
    "#                                                                dvs_imgs = False, ignore_seq = False, cnn = False)\n",
    "# acc_eclamp_base_noseq, val_acc_eclamp_noseq = run_keras_lowres_eclamp(res_list = RES_LIST, \n",
    "#                                                                timesteps = 5, random_dir = False, \n",
    "#                                                                dvs_imgs = False, ignore_seq = True, cnn = True)\n",
    "# acc_eclamp_base_dvs, val_acc_eclamp_dvs = run_keras_lowres_eclamp(res_list = RES_LIST, \n",
    "#                                                                timesteps = 5, random_dir = False, \n",
    "#                                                                dvs_imgs = True, ignore_seq = False, cnn = True)\n",
    "# acc_eclamp_base_dvs_nocnn, val_acc_eclamp_dvs_nocnn = run_keras_lowres_eclamp(res_list = RES_LIST, \n",
    "#                                                                timesteps = 5, random_dir = False, \n",
    "#                                                                dvs_imgs = True, ignore_seq = False, cnn = False)\n",
    "acc_eclamp_base_dvs_nocseq, val_acc_eclamp_dvs_noseq = run_keras_lowres_eclamp(res_list = RES_LIST, \n",
    "                                                               timesteps = 5, random_dir = False, \n",
    "                                                               dvs_imgs = True, ignore_seq = True, cnn = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(RES_LIST, val_acc_eclamp_base, 'ob')\n",
    "plt.plot(RES_LIST, val_acc_eclamp_nocnn, '*r')\n",
    "plt.plot(RES_LIST, val_acc_eclamp_noseq, 'ok')\n",
    "plt.plot(RES_LIST, val_acc_eclamp_dvs, 'og')\n",
    "plt.plot(RES_LIST, val_acc_eclamp_dvs_nocnn, 'oy')\n",
    "plt.plot(RES_LIST, val_acc_eclamp_dvs_noseq, '.g')\n",
    "plt.legend(['eclamp base','eclamp w/o cnn', 'eclamp w/o sequence', 'eclamp dvs','eclamp dvs w/o cnn', 'eclamp dvs w/o sequence'])\n",
    "plt.xlabel('res')\n",
    "plt.ylabel('val acc')\n",
    "# plt.savefig('eclamp_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.set_manual_q(starting_point)\n",
    "view0 = sensor.get_view(scene,agent)\n",
    "# view0.shape\n",
    "\n",
    "agent.set_manual_q(starting_point + [10,10])\n",
    "view1 = sensor.get_view(scene,agent)\n",
    "\n",
    "dvs_view = sensor.dvs_fun(view1,view0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(view0)\n",
    "plt.figure()\n",
    "plt.imshow(view1)\n",
    "plt.figure()\n",
    "plt.imshow(dvs_view)\n",
    "# view0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im=misc.build_mnist_padded(1./256*np.reshape(images[3],[1,28,28]))\n",
    "plt.figure()\n",
    "# plt.imshow(im)\n",
    "\n",
    "traj_1 = train_dataset_x[1][train_dataset_y==1,:,:]\n",
    "traj_0 = train_dataset_x[1][train_dataset_y==0,:,:]\n",
    "traj_2 = train_dataset_x[1][train_dataset_y==2,:,:]\n",
    "\n",
    "for seq in traj_0[:10]:\n",
    "    plt.plot(seq[:5,0],seq[:5,1], 'b')\n",
    "for seq in traj_1[:10]:\n",
    "    plt.plot(seq[:5,0],seq[:5,1], 'r')\n",
    "# for seq in traj_2[:10]:\n",
    "#     plt.plot(seq[:5,0],seq[:5,1], 'g')\n",
    "\n",
    "plt.axis('equal')\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(train_dataset_x[1][train_dataset_y==0,0,0], bins=20)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(train_dataset_x[1][train_dataset_y==1,0,0], bins=20)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(train_dataset_x[1][train_dataset_y==2,0,0], bins=20)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(train_dataset_x[1][train_dataset_y==3,0,0], bins=20)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(train_dataset_x[1][train_dataset_y==4,0,0], bins=20)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(train_dataset_x[1][train_dataset_y==5,0,0], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ind = 2\n",
    "# print(train_dataset_x[1][img_ind,:,:]-22)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset_x[0][img_ind,0,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset_x[0][img_ind,1,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset_x[0][img_ind,2,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset_x[0][img_ind,3,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset_x[0][img_ind,4,:,:,0])\n",
    "\n",
    "train_dataset_x[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = misc.build_mnist_padded(1./256*np.reshape(images[8],[1,28,28]))\n",
    "\n",
    "q = [36,36]\n",
    "view =  img[128 - q[1] - 56: 128 - q[1], q[0]: q[0] + 56]\n",
    "view_bad_res = bad_res101(view,(28,28))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(view_bad_res)\n",
    "print((view_bad_res==0.0).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indxs_empty = []\n",
    "sum_empty = 0\n",
    "for tx_ind, tx in enumerate(train_dataset_x):\n",
    "    for view in tx[:1]:\n",
    "#     for view in tx:\n",
    "#         plt.figure()\n",
    "#         plt.imshow(view)\n",
    "         sum_empty += (view==0).all()\n",
    "         if (view==0).all():\n",
    "             indxs_empty.append(tx_ind)\n",
    "\n",
    "print(sum_empty) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = rnn.predict(test_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_digit = []\n",
    "for sample_pred in test_predictions:\n",
    "    pred = np.where(sample_pred == np.max(sample_pred))\n",
    "    predicted_digit.append(pred[0][0])\n",
    "\n",
    "predicted_digit = np.array(predicted_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = 1\n",
    "np.sum(predicted_digit[test_dataset_y==digit]==digit)/np.sum(test_dataset_y==digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_x[1][0,:,:])\n",
    "print(traj_l[0])\n",
    "# plt.figure()\n",
    "# plt.plot(traj_l[1][:,0],traj_l[1][:,1], 'b')\n",
    "# len(train_dataset[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np_frame_filename = \"./mnist_100.npz\"\n",
    "\n",
    "# Load the NumPy array mini-batch from the saved .npz file\n",
    "data = np.load(np_frame_filename)\n",
    "print(data['x1'].shape)\n",
    "print(data['y'].shape)\n",
    "\n",
    "# data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a sample to plot\n",
    "sample = 0\n",
    "image = data['x1'][sample]\n",
    "# plot the sample\n",
    "fig = plt.figure()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "print(data['y'][sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(data['x1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_cnt = 100\n",
    "max_q = 56\n",
    "eclamp_substep_r = 0.5\n",
    "phi = np.pi/2.0\n",
    "q1_ana = [39,36]\n",
    "\n",
    "for i in range(20):\n",
    "            \n",
    "    q1_ana[0] = q1_ana[0] + eclamp_substep_r * np.cos(phi)\n",
    "    q1_ana[1] = q1_ana[1] + eclamp_substep_r * np.sin(phi)\n",
    "            \n",
    "    q1_ana = np.minimum(q1_ana,max_q) # enforce_bounderies ??\n",
    "    q1_ana = np.maximum(q1_ana,[0.0, 0.0])\n",
    "    q1 = np.int32(np.round(q1_ana))\n",
    "    \n",
    "    print(q1_ana,q1)\n",
    "#      if (q1 != q0).any():\n",
    "#                 agent.set_manual_q(q1)\n",
    "#     #             self.update(scene,agent)\n",
    "#                 view1 = self.get_view(scene,agent)\n",
    "#                 view1_cw = view1[self.cwy1:self.cwy2,self.cwx1:self.cwx2]\n",
    "#                 dvs_view = self.dvs_fun(view1_cw, view0_cw)\n",
    "#                 evnt_cnt = np.sum(np.abs(dvs_view))\n",
    "\n",
    "#             substeps+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imagewalker-cpu)",
   "language": "python",
   "name": "imagewalker-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
