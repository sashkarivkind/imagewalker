{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5, 38)\n",
      "debu return sequence True\n",
      "WARNING:tensorflow:From /home/bnapp/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "debug_shapes: (?, 5, 10)\n",
      "debug_shapes: (?, 5)\n",
      "debug_shapes: (?, 5, 10)\n",
      "debug_shapes: (?, 5)\n",
      "WARNING:tensorflow:From /home/bnapp/arivkindNet/rlnet1/keras_networks.py:23: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Are we random? 18\n",
      "debu0 [[36 36]\n",
      " [37 41]\n",
      " [37 41]\n",
      " [37 46]\n",
      " [32 46]]\n",
      "Fit model on training data\n",
      "WARNING:tensorflow:From /home/bnapp/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 2.0993 - time_distributed_accuracy: 0.2507 - time_distributed_accuracy_last_step: 0.2599 - val_loss: 1.7162 - val_time_distributed_accuracy: 0.4121 - val_time_distributed_accuracy_last_step: 0.4774\n",
      "Are we random? 12\n",
      "epoch 1  alpha 0.01 first q -- [36 36 37 40 37 40 37 45 32 45]\n",
      "Fit model on training data\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 1.6782 - time_distributed_accuracy: 0.4203 - time_distributed_accuracy_last_step: 0.4785 - val_loss: 1.5398 - val_time_distributed_accuracy: 0.4692 - val_time_distributed_accuracy_last_step: 0.5359\n",
      "Are we random? 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4cad556ef562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mnist_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_res_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbad_res102\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_datasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_trajectories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macceleration_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macceleration_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mtrain_dataset_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mtest_dataset_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/arivkindNet/rlnet1/curriculum_utils.py\u001b[0m in \u001b[0;36mcreate_mnist_dataset\u001b[0;34m(images, labels, res, sample, mixed_state, add_traject, q_0, alpha, trajectory_list, random_trajectories, return_datasets, add_seed, show_fig, mix_res, bad_res_func, up_sample, acceleration_mode)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0msensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;31m############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m#############CHANGED FROM sensor.central_frame_view TO sensor.frame_view####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/arivkindNet/rlnet1/SYCLOP_env.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, scene, agent)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mcurrent_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdvs_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdvs_view\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfading_mem\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdvs_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentral_dvs_view\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdvs_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwy1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwy2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/arivkindNet/rlnet1/SYCLOP_env.py\u001b[0m in \u001b[0;36mget_view\u001b[0;34m(self, scene, agent)\u001b[0m\n\u001b[1;32m    108\u001b[0m            agent.q[0]: agent.q[0]+self.hp.winx]\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_fun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/arivkindNet/rlnet1/curriculum_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             sensor = syc.Sensor(winx=56, winy=56, centralwinx=res // 2, centralwiny=res // 2,\n\u001b[0;32m--> 110\u001b[0;31m                                 resolution_fun=lambda x: bad_res_func(x, (res, res)), resolution_fun_type='down')\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwiny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/arivkindNet/rlnet1/curriculum_utils.py\u001b[0m in \u001b[0;36mbad_res102\u001b[0;34m(img, res)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbad_res102\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0msh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mdwnsmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdwnsmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from misc import HP\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import copy\n",
    "import SYCLOP_env as syc\n",
    "from misc import *\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras_networks import rnn_model_102e\n",
    "from curriculum_utils import create_mnist_dataset, bad_res102\n",
    "\n",
    "# ArgumentParser()\n",
    "def split_dataset_xy(dataset):\n",
    "    dataset_x1 = [uu[0] for uu in dataset]\n",
    "    dataset_x2 = [uu[1] for uu in dataset]\n",
    "    dataset_y = [uu[-1] for uu in dataset]\n",
    "    return (np.array(dataset_x1)[...,np.newaxis],np.array(dataset_x2)[:,:n_timesteps,:]), np.repeat(np.reshape(dataset_y,[-1,1]),hp.steps_per_episode,axis=1)\n",
    "\n",
    "#parse hyperparameters\n",
    "\n",
    "lsbjob = os.getenv('LSB_JOBID')\n",
    "lsbjob = '' if lsbjob is None else lsbjob\n",
    "\n",
    "hp = HP()\n",
    "hp.save_path = 'saved_runs'\n",
    "hp.description=''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--tau_int', default=4., type=float, help='Integration timescale for adaaptation')\n",
    "parser.add_argument('--resize', default=1.0, type=float, help='resize of images')\n",
    "parser.add_argument('--run_name_suffix', default='', type=str, help='suffix for runname')\n",
    "parser.add_argument('--eval_dir', default=None, type=str, help='eval dir')\n",
    "\n",
    "parser.add_argument('--dqn_initial_network', default=None, type=str, help='dqn_initial_network')\n",
    "parser.add_argument('--decoder_initial_network', default=None, type=str, help='decoder_initial_network')\n",
    "parser.add_argument('--decoder_learning_rate',  default=1e-3, type=float, help='decoder learning rate')\n",
    "parser.add_argument('--decoder_dropout',  default=0.0, type=float, help='decoder dropout')\n",
    "parser.add_argument('--decoder_rnn_type',  default='gru', type=str, help='gru or rnn')\n",
    "parser.add_argument('--decoder_rnn_units',  default=100, type=int, help='decoder rnn units')\n",
    "parser.add_argument('--decoder_rnn_layers',  default=1, type=int, help='decoder rnn units')\n",
    "\n",
    "\n",
    "parser.add_argument('--decoder_ignore_position', dest='decoder_ignore_position', action='store_true')\n",
    "parser.add_argument('--no-decoder_ignore_position', dest='decoder_ignore_position', action='store_false')\n",
    "\n",
    "parser.add_argument('--syclop_learning_rate',  default=2.5e-3, type=float, help='syclop (RL) learning rate')\n",
    "\n",
    "parser.add_argument('--color', default='grayscale', type=str, help='grayscale/rgb')\n",
    "parser.add_argument('--speed_reward',  default=0.0, type=float, help='speed reward, typically negative')\n",
    "parser.add_argument('--intensity_reward',  default=0.0, type=float, help='speed penalty reward')\n",
    "parser.add_argument('--loss_reward',  default=-1.0, type=float, help='reward for loss, typically negative')\n",
    "parser.add_argument('--resolution',  default=6, type=int, help='resolution')\n",
    "parser.add_argument('--max_eval_episodes',  default=10000, type=int, help='episodes for evaluation mode')\n",
    "parser.add_argument('--steps_per_episode',  default=5, type=int, help='time steps in each episode in ')\n",
    "parser.add_argument('--fit_verbose',  default=1, type=int, help='verbose level for model.fit                        ')\n",
    "parser.add_argument('--steps_between_learnings',  default=100, type=int, help='steps_between_learnings')\n",
    "parser.add_argument('--num_epochs',  default=100, type=int, help='steps_between_learnings')\n",
    "\n",
    "parser.add_argument('--alpha_increment',  default=0.01, type=float, help='reward for loss, typically negative')\n",
    "\n",
    "\n",
    "parser.add_argument('--beta_t1',  default=400000, type=int, help='time rising bete')\n",
    "parser.add_argument('--beta_t2',  default=700000, type=int, help='end rising beta')\n",
    "parser.add_argument('--beta_b1',  default=0.1, type=float, help='beta initial value')\n",
    "parser.add_argument('--beta_b2',  default=1.0, type=float, help='beta final value')\n",
    "\n",
    "parser.add_argument('--curriculum_enable', dest='curriculum_enable', action='store_true')\n",
    "parser.add_argument('--no-curriculum_enable', dest='curriculum_enable', action='store_false')\n",
    "\n",
    "parser.add_argument('--conv_fe', dest='conv_fe', action='store_true')\n",
    "parser.add_argument('--no-conv_fe', dest='conv_fe', action='store_false')\n",
    "\n",
    "parser.add_argument('--acceleration_mode', dest='acceleration_mode', action='store_true')\n",
    "parser.add_argument('--no-acceleration_mode', dest='acceleration_mode', action='store_false')\n",
    "\n",
    "\n",
    "parser.set_defaults(eval_mode=False, decode_from_dvs=False,test_mode=False,rising_beta_schedule=True,decoder_ignore_position=False, curriculum_enable=True, conv_fe=False,\n",
    "                    acceleration_mode=False)\n",
    "\n",
    "config = parser.parse_args('')\n",
    "config = vars(config)\n",
    "hp.upadte_from_dict(config)\n",
    "hp.this_run_name = sys.argv[0] + '_noname_' + hp.run_name_suffix + '_' + lsbjob + '_' + str(int(time.time()))\n",
    "\n",
    "#define model\n",
    "n_timesteps = hp.steps_per_episode\n",
    "\n",
    "##\n",
    "# deploy_logs()\n",
    "##\n",
    "decoder = rnn_model_102e(lr=hp.decoder_learning_rate,ignore_input_B=hp.decoder_ignore_position,dropout=hp.decoder_dropout,rnn_type=hp.decoder_rnn_type,\n",
    "                                input_size=(hp.resolution,hp.resolution, 1),rnn_layers=hp.decoder_rnn_layers,conv_fe=hp.conv_fe)\n",
    "# decoder = keras.models.load_model(hp.decoder_initial_network)\n",
    "#define dataset\n",
    "(images, labels), (images_test, labels_test) = keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "\n",
    "#fit one epoch in a  time\n",
    "# scheduler = Scheduler(hp.lambda_schedule)\n",
    "# for epoch in range(hp.num_epochs):\n",
    "#     lambda_epoch = scheduler.step(epoch)\n",
    "alpha=0\n",
    "for epoch in range(hp.num_epochs):\n",
    "    if hp.curriculum_enable:\n",
    "        if epoch == 0:\n",
    "            train_dataset, test_dataset = create_mnist_dataset(images, labels, 6, bad_res_func=bad_res102, return_datasets=True, q_0=0, alpha=1.0,random_trajectories=False,acceleration_mode=hp.acceleration_mode)\n",
    "            train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset)\n",
    "            test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset)\n",
    "            q_0=train_dataset_x[1][0]\n",
    "            print('debu0',q_0)\n",
    "        else:\n",
    "            alpha += hp.alpha_increment\n",
    "            alpha = np.minimum(alpha,1.0)\n",
    "\n",
    "            train_dataset, test_dataset = create_mnist_dataset(images, labels, 6, bad_res_func=bad_res102, return_datasets=True, q_0=q_0, alpha=alpha,random_trajectories=True,acceleration_mode=hp.acceleration_mode)\n",
    "            train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset)\n",
    "            test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset)\n",
    "            q_prime=train_dataset_x[1][0]\n",
    "            print('epoch',epoch,' alpha',alpha,'first q --', q_prime.reshape([-1]))\n",
    "    else:\n",
    "        train_dataset, test_dataset = create_mnist_dataset(images, labels, 6, bad_res_func=bad_res102,\n",
    "                                                           return_datasets=True, q_0=0, alpha=1.0,\n",
    "                                                           random_trajectories=True,acceleration_mode=hp.acceleration_mode)\n",
    "        train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset)\n",
    "        test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset)\n",
    "        q_prime = train_dataset_x[1][0]\n",
    "        print('epoch', epoch, '  CONTROL!!!',' first q --', q_prime.reshape([-1]))\n",
    "        print('epoch', epoch, '  CONTROL!!!',' first im --', train_dataset_x[0][0])\n",
    "\n",
    "    print(\"Fit model on training data\")\n",
    "    history = decoder.fit(\n",
    "        train_dataset_x,\n",
    "        train_dataset_y,\n",
    "        batch_size=135,\n",
    "        epochs=1,\n",
    "        verbose=hp.fit_verbose,\n",
    "        # We pass some validation for\n",
    "        # monitoring validation loss and metrics\n",
    "        # at the end of each epoch\n",
    "        validation_data=(test_dataset_x, test_dataset_y)  # (validation_images, validation_labels)\n",
    "        )\n",
    "\n",
    "#save the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argparse.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = parser.parse_args('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            train_dataset, test_dataset = create_mnist_dataset(images, labels, 6, bad_res_func=bad_res102, return_datasets=True, q_0=0, alpha=1.0,random_trajectories=False,acceleration_mode=hp.acceleration_mode)\n",
    "            train_dataset_x, train_dataset_y = split_dataset_xy(train_dataset)\n",
    "            test_dataset_x, test_dataset_y = split_dataset_xy(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
