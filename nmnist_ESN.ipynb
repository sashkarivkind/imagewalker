{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import networkx as nx\n",
    "from quantities import ms\n",
    "from ebdataset.vision import NMnist\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ebdataset.vision.transforms import Compose, ToDense, Flatten\n",
    "\n",
    "from module_utils import graph_to_tensor\n",
    "\n",
    "try:\n",
    "    set_start_method(\"spawn\")\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "import sys\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets\n",
    "import echotorch.nn.reservoir\n",
    "#from echotorch.nn.reservoir.ESN import ESN\n",
    "\n",
    "\n",
    "\n",
    "class ESN(nn.Module):\n",
    "    '''\n",
    "    Addopted from - \n",
    "    N. Schaetti, M. Salomon, and R. Couturier,\n",
    "    Echo state networks-basedreservoir computing for mnist handwritten digits recognition\n",
    "    https://ieeexplore-ieee-org.ezproxy.weizmann.ac.il/abstract/document/7982291\n",
    "    '''\n",
    "    def __init__(self, input_dim,\n",
    "                 reservoir_size,\n",
    "                 output_dim,\n",
    "                 batch_size,\n",
    "                 leaky_rate, \n",
    "                 w_in = None, \n",
    "                 w_rec = None, \n",
    "                 w_out = None,\n",
    "                 w_bias = None,\n",
    "                 tau = 0.2,\n",
    "                 noise = False,\n",
    "                 decaying_output = False):\n",
    "        super().__init__()\n",
    "        #create input layer from input to reservoir\n",
    "        self.input_layer = nn.Linear(input_dim, reservoir_size)\n",
    "        \n",
    "        if w_in is not None:\n",
    "            with torch.no_grad():\n",
    "                self.input_layer.weight = nn.Parameter(w_in)\n",
    "        #creat recuurent connections in the reservoir\n",
    "        if w_rec is None:            \n",
    "            #Some numbers from - \n",
    "            #Goudar and Buonomano. eLife 2018;7:e31134. DOI: https://doi.org/10.7554/eLife.31134\n",
    "            #create a random fully connected layer\n",
    "            self.w_rec = torch.normal(0,1.6,size = (reservoir_size,reservoir_size))\n",
    "            self.w_rec = torch.normal(0,1.6,size = (reservoir_size,reservoir_size))\n",
    "            #Set connectiviy to 20%\n",
    "            mask = torch.rand([reservoir_size,reservoir_size]) < 0.2\n",
    "            self.w_rec *= mask\n",
    "            \n",
    "        else:\n",
    "            self.w_rec =nn.Parameter( w_rec)\n",
    "            \n",
    "        \n",
    "        #create reservoir state at reset = 0, with size (batch_size,reservoir_size)\n",
    "        #to hold the states for each different example in the batch. \n",
    "        self.echo_state = torch.zeros((batch_size,reservoir_size))\n",
    "        \n",
    "        #Create readout layer\n",
    "        self.output_layer = nn.Linear(reservoir_size, output_dim)\n",
    "        \n",
    "        #Create a output state to hold the states for the decaying output option\n",
    "        self.output = torch.zeros((batch_size, output_dim))\n",
    "        if w_out is not None:\n",
    "            with torch.no_grad():\n",
    "                self.output_layer.weight = nn.Parameter(w_out)\n",
    "\n",
    "        self.w_bias = w_bias \n",
    "        self.non_linearity = torch.tanh\n",
    "        self.noise = noise\n",
    "        self.tau = tau\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_dim = output_dim\n",
    "        self.decaying_output = decaying_output\n",
    "        \n",
    "        self.w_rec_out = nn.Linear(self.output_dim,self.output_dim)\n",
    "        with torch.no_grad():\n",
    "            self.w_rec_out.weight = nn.Parameter(self.tau * torch.eye(self.output_dim,requires_grad=True))\n",
    "        #self.output_rnn = nn.RNN(self.reservoir_size,self.output_dim)\n",
    "        #with torch.no_grad():\n",
    "        #    self.output_rnn.RNN.weight_hh_l = \\\n",
    "        #        nn.Parameter(self.tau * torch.eye((self.output_dim, self.output_dim)))\n",
    "    def forward(self,x):\n",
    "        \n",
    "        #Compute the increament from the next input and the reccurent state\n",
    "        #This is exactly (right?) like the nn.RNN function, I need to try \n",
    "        #running with this as well and see what happens.\n",
    "        with torch.no_grad():\n",
    "            next_state = self.input_layer(x) +\\\n",
    "                        F.linear(self.echo_state.double(),self.w_rec.double(),self.w_bias) \n",
    "\n",
    "        #Add noise if defined\n",
    "        if self.noise:\n",
    "            next_state += self.noise\n",
    "                \n",
    "        #Add non-linearity\n",
    "        next_state = self.non_linearity(next_state)\n",
    "        \n",
    "        #Update echo state with tau\n",
    "        self.echo_state += -torch.mul(self.echo_state, self.tau) +\\\n",
    "                            torch.mul(next_state, self.tau)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.decaying_output:\n",
    "            self.output = self.w_rec_out(self.output)\n",
    "            self.output = self.output_layer(self.echo_state)\n",
    "                \n",
    "        else:\n",
    "            self.output = self.output_layer(self.echo_state)\n",
    "        \n",
    "        return self.output \n",
    "    \n",
    "    def reset_reservoir(self, batch_size):\n",
    "        ''' \n",
    "        Reset the reservoir state to 0 after object has passed.\n",
    "        This is helpful but redundant, I guess we can look at the state\n",
    "        after some delta t where the past states are no longer relevant\n",
    "        NEED to experiment with this. \n",
    "        '''\n",
    "        self.echo_state = torch.zeros((batch_size,self.reservoir_size))\n",
    "        self.output = torch.zeros((batch_size, self.output_dim))\n",
    "    \n",
    "\n",
    "\n",
    "# Experiment parameters\n",
    "reservoir_size = 500\n",
    "connectivity = 0.1\n",
    "spectral_radius = 1.3\n",
    "leaky_rate = 0.2\n",
    "batch_size = 60\n",
    "input_scaling = 0.6\n",
    "ridge_param = 0.0\n",
    "bias_scaling = 1.0\n",
    "image_time = 15 #How many time steps for each image\n",
    "input_size = 34 * 34 * 2 #The image is flatten to a vector\n",
    "n_digits = 10\n",
    "training_size = 60000\n",
    "test_size = 10000\n",
    "use_cuda = False #and torch.cuda.is_available()\n",
    "\n",
    "import os\n",
    "\n",
    "def collate_fn(samples):\n",
    "    max_duration = max([s[0].shape[-1] for s in samples])\n",
    "    batch = torch.zeros(len(samples), 34 * 34 * 2, max_duration)\n",
    "    labels = []\n",
    "    for i, s in enumerate(samples):\n",
    "        batch[i, :, : s[0].shape[-1]] = s[0]\n",
    "        labels.append(s[1])\n",
    "    return batch, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Internal matrix\n",
    "w_generator = echotorch.utils.matrix_generation.NormalMatrixGenerator(\n",
    "    connectivity=connectivity,\n",
    "    spetral_radius=spectral_radius\n",
    ")\n",
    "\n",
    "# Input weights\n",
    "win_generator = echotorch.utils.matrix_generation.NormalMatrixGenerator(\n",
    "    connectivity=connectivity,\n",
    "    scale=input_scaling,\n",
    "    apply_spectral_radius=False\n",
    "    )\n",
    "\n",
    "# Bias vector\n",
    "wbias_generator = echotorch.utils.matrix_generation.NormalMatrixGenerator(\n",
    "    connectivity=connectivity,\n",
    "    scale=bias_scaling,\n",
    "    apply_spectral_radius=False\n",
    "     )\n",
    "\n",
    "# New ESN-JS module\n",
    "esn = ESN(\n",
    "    #Input w, num of columns, the ESN is fed row by row so the number of\n",
    "    #columns is the number of inputs to the ESN in each ts.\n",
    "    input_dim=input_size,\n",
    "    #Input h, num of rows\n",
    "    #image_size=image_size,\n",
    "    reservoir_size=reservoir_size,\n",
    "    batch_size = batch_size,\n",
    "    leaky_rate=leaky_rate,\n",
    "    #ridge_param=ridge_param,\n",
    "    output_dim=10,\n",
    "    w_in=win_generator.generate(size=(input_size, reservoir_size)).T.float(),\n",
    "    w_rec=w_generator.generate(size=(reservoir_size, reservoir_size)).T,\n",
    "    w_bias=wbias_generator.generate(size=(reservoir_size)).T,\n",
    "    decaying_output=False\n",
    "     )\n",
    "\n",
    "# Show the model\n",
    "\n",
    "print(esn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"collate_fn\": collate_fn,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "dt = 1 * ms\n",
    "\n",
    "\n",
    "transforms = Compose([ToDense(dt=dt), Flatten(),])\n",
    "\n",
    "NMNIST_PATH = \"/home/orram/Documents/NMNIST\"\n",
    "OUT_DIR = \"/home/orram/Documents/NMNIST/nmnist_output\"\n",
    "\n",
    "training_set = NMnist(NMNIST_PATH, is_train=True, transforms=transforms)\n",
    "train_loader = data.DataLoader(training_set, **params)\n",
    "\n",
    "test_set = NMnist(NMNIST_PATH, is_train=False, transforms=transforms)\n",
    "test_loader = data.DataLoader(test_set, **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "optimizer = optim.SGD(esn.parameters(), lr = lr)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "linear_regression = nn.Sequential(nn.Linear(reservoir_size*3,10))\n",
    "linear_loss = nn.CrossEntropyLoss()\n",
    "linear_optimizer = optim.SGD(linear_regression.parameters(), lr)\n",
    "\n",
    "epochs = 1\n",
    "training_size = len(train_loader)*epochs*60\n",
    "train_loss = []\n",
    "accur_vote = []\n",
    "accur_max = []\n",
    "accur_mts = []\n",
    "echo_all_memory = []\n",
    "with tqdm(total=training_size,position=0, leave=True) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        batch_loss = []\n",
    "        joint_loss = []\n",
    "        max_loss = []\n",
    "        mts_loss_vec = []\n",
    "        for i, (batch, labels) in enumerate(train_loader):\n",
    "            batch = batch.squeeze(1)\n",
    "            esn.reset_reservoir(batch_size = batch.shape[0] )\n",
    "            labels = labels.reshape(batch.shape[0])\n",
    "            spikes = []\n",
    "            t_loss = []\n",
    "            #A place holder to store the classification from each time step \n",
    "            #after the run over the image we take the max class, the one who got\n",
    "            #the most votes! This we call equal voting, each run donates \n",
    "            #all the probabilities for class 1 to 10 and the desigion happens\n",
    "            #after all the image is processed\n",
    "            vote = torch.zeros((batch.shape[0],10))\n",
    "            #Another option is only to take the class that got the \n",
    "            #most probability and sum over these predictions and drew \n",
    "            #the one that got the most votes. This is only max  vote. \n",
    "            #The last option - MTS - is described below.\n",
    "            only_max_vote = torch.zeros((batch.shape[0],10))\n",
    "            state_memory = torch.empty([batch.shape[0],3*reservoir_size])\n",
    "            s = []\n",
    "            ind = 0\n",
    "            for t in range(len(batch[0,0,:])):\n",
    "                \n",
    "                #insert the inputs line by line (time step by time step)\n",
    "                optimizer.zero_grad()\n",
    "                output = esn(batch[:, :, t])\n",
    "                esn.output *= esn.tau\n",
    "                loss = loss_func(output,labels )\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                spikes.append(esn.echo_state)\n",
    "                t_loss.append(loss.item())\n",
    "                vote += output\n",
    "                one_hot = torch.nn.functional.one_hot(torch.argmax(output,axis = 1), num_classes = 10)\n",
    "                only_max_vote += one_hot\n",
    "                '''\n",
    "                Impliment mixed three state (MTS)- \n",
    "                We keep three states from the esn and compute the classification \n",
    "                from the unification of these states.\n",
    "                We choose the state after t=T/3, 2T/3, T\n",
    "                The layer to feed to the classifier is then (3*reservoir_size).\n",
    "                To do this we define a new linear reggresser\n",
    "                accur_\n",
    "                '''\n",
    "                \n",
    "                if t == np.round(len(batch[0,0,:])/3) or \\\n",
    "                    t == np.round(len(batch[0,0,:])*2/3) or \\\n",
    "                        t == len(batch[0,0,:]) - 1 :\n",
    "                            state_memory[:,ind:ind+reservoir_size] = esn.echo_state\n",
    "                            s.append(esn.echo_state.detach().numpy())\n",
    "                            ind+=reservoir_size\n",
    "                            \n",
    "            #Run the optimizer over MTS       \n",
    "            linear_optimizer.zero_grad()\n",
    "            mts_output = linear_regression(state_memory)\n",
    "            mts_loss = linear_loss(mts_output, labels)\n",
    "            mts_loss.backward()\n",
    "            linear_optimizer.step()\n",
    "            mts_loss_vec.append(mts_loss.item())\n",
    "            echo_all_memory.append((state_memory, labels))\n",
    "            \n",
    "            \n",
    "            get_max = torch.argmax(vote, axis = 1)\n",
    "            joint_loss.append(loss_func(vote, labels).item())\n",
    "            max_loss.append(loss_func(only_max_vote/len(only_max_vote), labels).item())\n",
    "            batch_loss.append(np.mean(t_loss))\n",
    "            spikes = torch.stack(spikes, dim=2)\n",
    "            #joblib.dump(\n",
    "            #    (spikes.cpu().numpy(), labels.cpu().numpy()),\n",
    "            #    os.path.join(OUT_DIR, \"%s_batch_%i\" % (\"TRAIN\", i)),\n",
    "            #    compress=3,\n",
    "            #    )\n",
    "            get_vote = torch.argmax(vote, axis = 1)\n",
    "            get_max = torch.argmax(only_max_vote, axis = 1)\n",
    "            correct_vote = sum(get_vote.detach().numpy() == labels.detach().numpy())\n",
    "            correct_max = sum(get_max.detach().numpy() == labels.detach().numpy())\n",
    "            accur_vote.append(correct_vote/batch.shape[0])\n",
    "            \n",
    "            accur_max.append(correct_max/batch.shape[0])\n",
    "            mts_output = linear_regression(state_memory)\n",
    "            get_mts = torch.argmax(mts_output, axis = 1)\n",
    "            correct_mts = sum(get_mts == labels)\n",
    "            accur_mts.append(correct_mts/batch.shape[0])\n",
    "            pbar.update(batch_size)\n",
    "            \n",
    "        train_loss.append(np.mean(batch_loss))\n",
    "        \n",
    "pbar.close()\n",
    "print('train loss = equal vote = {} max vote only = {} and mts = {} '.format\\\n",
    "      (joint_loss[-1], max_loss[-1], mts_loss_vec[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
